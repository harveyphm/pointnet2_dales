{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy as lp\n",
    "import pdal\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm laspy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is pre-split into 29 training files and 11 testing files, with the following categories: ground(1), vegetation(2), cars(3), trucks(4), power lines(5), fences(6), poles(7) and buildings(8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputfile, outputfile, tile_size=100, num_neighbors=15):\n",
    "    #Since in DALES, ground classification is 1, we need to switch it to 2\n",
    "    pipe1 = {\n",
    "            \"pipeline\":[\n",
    "            {\n",
    "                \"type\": \"readers.las\",\n",
    "                \"filename\": inputfile,\n",
    "                \"spatialreference\": \"EPSG:32615\"\n",
    "            },\n",
    "            #Modify the classification values to make ground 2, adjust it based on \n",
    "            #the classification values of your dataset\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 9 WHERE Classification == 2\"]\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 2 WHERE Classification == 1\"]\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 1 WHERE Classification == 9\"]\n",
    "            },\n",
    "            #End of classification modification\n",
    "            {\n",
    "                \"type\": \"filters.hag_delaunay\",\n",
    "                \"count\": num_neighbors,\n",
    "            },\n",
    "            # Change the classifiiers to the ones in your dataset\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 9 WHERE Classification == 2\"]\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 2 WHERE Classification == 1\"]\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"value\": [\"Classification = 1 WHERE Classification == 9\"]\n",
    "            },\n",
    "            #Tilting the point cloud\n",
    "            {\n",
    "                \"type\":\"filters.splitter\",\n",
    "                \"length\": tile_size\n",
    "                # \"origin_x\":\"638900.0\",\n",
    "                # \"origin_y\":\"835500.0\"\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"writers.las\",\n",
    "                \"filename\": outputfile\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "    jsonstring = json.dumps(pipe1)\n",
    "    p = pdal.Pipeline(jsonstring)\n",
    "    p.execute()\n",
    "    return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing las file: 5080_54435.las ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29 [01:51<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TILE_SIZE = 50\n",
    "DSET = \"train\"\n",
    "PREPROCESSING_DIR = f'dataset/dales_las/{DSET}'\n",
    "PREPROCESSED_DIR = f'tiles_{TILE_SIZE}/{DSET}'\n",
    "\n",
    "all_las_files = os.listdir(PREPROCESSING_DIR)\n",
    "\n",
    "\n",
    "print(\"Preprocessing started ...\")\n",
    "all_las_files = all_las_files[:2]\n",
    "for las_file in tqdm(all_las_files, total=len(all_las_files)):\n",
    "    print(f\"Preprocessing las file: {las_file} ...\")\n",
    "    in_path = os.path.join(PREPROCESSING_DIR, las_file)    \n",
    "\n",
    "    las_number = las_file.split(\".\")[0]\n",
    "    out_path = os.path.join(PREPROCESSED_DIR, f\"{las_number}_#.las\")\n",
    "    preprocess(in_path, out_path)\n",
    "\n",
    "print(\"Preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habakiri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
