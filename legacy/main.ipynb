{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2efa875-7897-4d1b-a54c-4db96ad21f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:42:36.464176Z",
     "iopub.status.busy": "2024-04-16T12:42:36.463626Z",
     "iopub.status.idle": "2024-04-16T12:42:36.476866Z",
     "shell.execute_reply": "2024-04-16T12:42:36.471837Z",
     "shell.execute_reply.started": "2024-04-16T12:42:36.464122Z"
    }
   },
   "outputs": [],
   "source": [
    "# !tar -xvzf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5403fa81-608c-4b08-8c95-b7f52726f66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:42:36.480983Z",
     "iopub.status.busy": "2024-04-16T12:42:36.479878Z",
     "iopub.status.idle": "2024-04-16T12:46:20.398283Z",
     "shell.execute_reply": "2024-04-16T12:46:20.396751Z",
     "shell.execute_reply.started": "2024-04-16T12:42:36.480925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cpu)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp38-cp38-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp38-cp38-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.3)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp38-cp38-linux_x86_64.whl (757.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.2)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.2\n",
      "    Uninstalling typing_extensions-4.6.2:\n",
      "      Successfully uninstalled typing_extensions-4.6.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1+cpu\n",
      "    Uninstalling torch-1.13.1+cpu:\n",
      "      Successfully uninstalled torch-1.13.1+cpu\n",
      "Successfully installed filelock-3.9.0 fsspec-2023.4.0 mpmath-1.3.0 networkx-3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-10.2.0 sympy-1.12 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121 triton-2.2.0 typing-extensions-4.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch-scatter 2.1.0+pt113cpu\n",
      "Uninstalling torch-scatter-2.1.0+pt113cpu:\n",
      "  Successfully uninstalled torch-scatter-2.1.0+pt113cpu\n",
      "Found existing installation: torch-sparse 0.6.16+pt113cpu\n",
      "Uninstalling torch-sparse-0.6.16+pt113cpu:\n",
      "  Successfully uninstalled torch-sparse-0.6.16+pt113cpu\n",
      "\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "poptorch-geometric 3.2.0+112435 requires torch-sparse@ https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_sparse-0.6.16+pt113cpu-cp38-cp38-linux_x86_64.whl, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyvis\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from pyvis) (7.16.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.8/dist-packages (from pyvis) (3.1.2)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Downloading jsonpickle-3.0.4-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.8/dist-packages (from pyvis) (3.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (2.2.2+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (67.8.0)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.17.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (3.0.38)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (2.15.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from jedi<=0.17.2,>=0.10->ipython>=5.3.0->pyvis) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, kiwisolver, jsonpickle, fonttools, cycler, contourpy, matplotlib, pyvis, torchmetrics\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.51.0 jsonpickle-3.0.4 kiwisolver-1.4.5 lightning-utilities-0.11.2 matplotlib-3.7.5 pyvis-0.3.2 torchmetrics-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting laspy\n",
      "  Downloading laspy-2.5.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from laspy) (1.24.3)\n",
      "Installing collected packages: laspy\n",
      "Successfully installed laspy-2.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting hydra-core\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core) (23.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core) (5.12.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (5.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core) (3.15.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144553 sha256=0a5ee68552f7ccfb044b685e3eb982154cba2b10a5767639bf57d6b3384dbddd\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse torch-cluster -y\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install matplotlib pyvis torchmetrics\n",
    "!pip install laspy\n",
    "!pip install hydra-core \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fef1e0d-16b3-42af-8131-6cb6e9bfe31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:20.403944Z",
     "iopub.status.busy": "2024-04-16T12:46:20.403431Z",
     "iopub.status.idle": "2024-04-16T12:46:21.030846Z",
     "shell.execute_reply": "2024-04-16T12:46:21.028592Z",
     "shell.execute_reply.started": "2024-04-16T12:46:20.403900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 12:46:20 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P4000        Off  | 00000000:00:05.0 Off |                  N/A |\n",
      "| 46%   39C    P8     5W / 105W |      2MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9801aaa-1307-401b-a29d-e845a6deae6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:21.034324Z",
     "iopub.status.busy": "2024-04-16T12:46:21.033800Z",
     "iopub.status.idle": "2024-04-16T12:46:31.826258Z",
     "shell.execute_reply": "2024-04-16T12:46:31.824316Z",
     "shell.execute_reply.started": "2024-04-16T12:46:21.034280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "import os\n",
    "import laspy as lp\n",
    "import numpy as np\n",
    "import hydra\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import jaccard_index\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius,knn_interpolate\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ca5f13-f4ed-456b-b5ae-b284c930fcef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.829154Z",
     "iopub.status.busy": "2024-04-16T12:46:31.828483Z",
     "iopub.status.idle": "2024-04-16T12:46:31.839132Z",
     "shell.execute_reply": "2024-04-16T12:46:31.836425Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.829117Z"
    }
   },
   "outputs": [],
   "source": [
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7747aa-2382-4f89-a3a2-6b5cdeb1f32c",
   "metadata": {},
   "source": [
    "# Define PointNet++ Segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "72ce8472-4782-4289-9e3d-9cbf3161ef3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:36:38.123556Z",
     "iopub.status.busy": "2024-04-16T14:36:38.123200Z",
     "iopub.status.idle": "2024-04-16T14:36:38.131389Z",
     "shell.execute_reply": "2024-04-16T14:36:38.130082Z",
     "shell.execute_reply.started": "2024-04-16T14:36:38.123527Z"
    }
   },
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        \n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        \n",
    "        # print(f\"idx shape: {idx.shape}\")\n",
    "        # print(f\"x shape: {x.shape}\")\n",
    "        # print(f\"pos shape: {pos.shape}\")\n",
    "        # print(f\"x_dst shape: {x_dst.shape}\")\n",
    "        # print(f\"edge_index shape: {edge_index.shape}\")\n",
    "        \n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd03b64-c731-4e6c-b727-977fc5cd9ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.858817Z",
     "iopub.status.busy": "2024-04-16T12:46:31.858378Z",
     "iopub.status.idle": "2024-04-16T12:46:31.871663Z",
     "shell.execute_reply": "2024-04-16T12:46:31.869576Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.858781Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0b5e36-c0e8-4e10-929b-c26ea88eec07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.874908Z",
     "iopub.status.busy": "2024-04-16T12:46:31.874291Z",
     "iopub.status.idle": "2024-04-16T12:46:31.893143Z",
     "shell.execute_reply": "2024-04-16T12:46:31.889679Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.874859Z"
    }
   },
   "outputs": [],
   "source": [
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e071dfe-5e7e-4ba1-b7e4-9b66b04255ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:47:45.838281Z",
     "iopub.status.busy": "2024-04-16T13:47:45.837784Z",
     "iopub.status.idle": "2024-04-16T13:47:45.853959Z",
     "shell.execute_reply": "2024-04-16T13:47:45.851927Z",
     "shell.execute_reply.started": "2024-04-16T13:47:45.838249Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes , num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        # self.sa1_module = SAModule(0.2, 0.2, MLP([3 + 3, 64, 64, 128]))\n",
    "        self.sa1_module = SAModule(0.2, 0.2, MLP([3 + num_features, 64, 64, 128]))\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([1024 + 256, 256, 256]))\n",
    "        self.fp2_module = FPModule(3, MLP([256 + 128, 256, 128]))\n",
    "        self.fp1_module = FPModule(3, MLP([128 + num_features, 128, 128, 128]))\n",
    "\n",
    "        self.mlp = MLP([128, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        # self.lin1 = torch.nn.Linear(128, 128)\n",
    "        # self.lin2 = torch.nn.Linear(128, 128)\n",
    "        # self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "\n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30770fbd-1c1b-4c40-a044-aa74b6c9277b",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a492349-5e85-4638-aaac-88e611c5e505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.923037Z",
     "iopub.status.busy": "2024-04-16T12:46:31.922471Z",
     "iopub.status.idle": "2024-04-16T12:46:31.934544Z",
     "shell.execute_reply": "2024-04-16T12:46:31.932719Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.922990Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get all las file for training \n",
    "TRAIN_DIR = \"dales_las/train/\" \n",
    "TEST_DIR = \"dales_las/test/\"\n",
    "\n",
    "all_train_files = os.listdir(osp.abspath(TRAIN_DIR))\n",
    "all_test_files  = os.listdir(osp.abspath(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08cff59-f71c-4af2-ba82-ee324e479b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.936818Z",
     "iopub.status.busy": "2024-04-16T12:46:31.936274Z",
     "iopub.status.idle": "2024-04-16T12:46:33.135232Z",
     "shell.execute_reply": "2024-04-16T12:46:33.133618Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.936743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Y\n",
      "Z\n",
      "intensity\n",
      "return_number\n",
      "number_of_returns\n",
      "scan_direction_flag\n",
      "edge_of_flight_line\n",
      "classification\n",
      "synthetic\n",
      "key_point\n",
      "withheld\n",
      "scan_angle_rank\n",
      "user_data\n",
      "point_source_id\n",
      "gps_time\n"
     ]
    }
   ],
   "source": [
    "pc = lp.read(os.path.join(TRAIN_DIR, all_train_files[0])) \n",
    "for dimension in pc.point_format.dimensions:\n",
    "    print(dimension.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f03475d5-736b-4e36-a093-48b40530e03c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:29:05.574382Z",
     "iopub.status.busy": "2024-04-16T14:29:05.573803Z",
     "iopub.status.idle": "2024-04-16T14:29:05.588429Z",
     "shell.execute_reply": "2024-04-16T14:29:05.586645Z",
     "shell.execute_reply.started": "2024-04-16T14:29:05.574350Z"
    }
   },
   "outputs": [],
   "source": [
    "def convertData(pc, debug = False):\n",
    "    #Define preprocessing steps\n",
    "    # num_to_load = -1\n",
    "    transform = T.Compose([\n",
    "        T.RandomJitter(0.01),\n",
    "        T.RandomRotate(15, axis=0),\n",
    "        T.RandomRotate(15, axis=1),\n",
    "        T.RandomRotate(15, axis=2)\n",
    "        ])\n",
    "    pre_transform = T.NormalizeScale()\n",
    "    \n",
    "    #Get imformation from las file\n",
    "    coords = np.vstack((pc.x, pc.y, pc.z)).transpose()    \n",
    "    scales = pc.header.scales\n",
    "    offsets= pc.header.offsets    \n",
    "    scaled_coords = (coords * scales) + offsets\n",
    "    \n",
    "    labels = pc.classification.array\n",
    "    features = pc.intensity if np.max(pc.intensity) > 0 else np.ones_like(pc.intensity, dtype = np.uint8)\n",
    "    if len(features.shape) <2: \n",
    "        features = features[:, np.newaxis]\n",
    "    num_classes = len(np.unique(labels))\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print(features.shape)\n",
    "        print(coords.shape)\n",
    "        print(scaled_coords.shape)\n",
    "        print(labels.shape)\n",
    "        print(np.unique(labels))\n",
    "    return Data(x = torch.from_numpy(features), \n",
    "                pos = torch.from_numpy(scaled_coords).type(torch.FloatTensor), \n",
    "                y = torch.from_numpy(labels), \n",
    "                num_classes=num_classes,\n",
    "                num_features = features.shape[-1],\n",
    "               transform = transform, \n",
    "               pre_transform= pre_transform,\n",
    "               batch = torch.from_numpy(np.zeros_like(features,dtype = np.int64)).flatten()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1a6deb8-9cb6-43b2-972f-6d8298fcd1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:29:08.355152Z",
     "iopub.status.busy": "2024-04-16T14:29:08.354604Z",
     "iopub.status.idle": "2024-04-16T14:29:08.369150Z",
     "shell.execute_reply": "2024-04-16T14:29:08.367374Z",
     "shell.execute_reply.started": "2024-04-16T14:29:08.355107Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchLoader(): \n",
    "    def __init__(self, pc, batch_size = 32000):\n",
    "        self.data = convertData(pc) \n",
    "        self.batch_size = batch_size \n",
    "        self.num_points  = int(self.data.x.shape[0])\n",
    "        self.num_batches =  self.num_points // self.batch_size\n",
    "        \n",
    "        print(self.data.x.shape[0])\n",
    "        \n",
    "    def load(self):\n",
    "        batches = []\n",
    "        for i in range(self.num_batches+1):\n",
    "            start_indx = int(i*self.batch_size)\n",
    "            end_indx   = start_indx + self.batch_size if  (start_indx + self.batch_size) < self.num_points else self.num_points\n",
    "    \n",
    "            batches.append(\n",
    "                Data(\n",
    "                    x = self.data.x[start_indx:end_indx], \n",
    "                    pos = self.data.pos[start_indx:end_indx], \n",
    "                    y = self.data.y[start_indx:end_indx], \n",
    "                    batch = self.data.batch[start_indx:end_indx]))\n",
    "                \n",
    "        return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de12317c-95fd-49e3-820d-1870133baa4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:35:31.789417Z",
     "iopub.status.busy": "2024-04-16T14:35:31.788848Z",
     "iopub.status.idle": "2024-04-16T14:35:36.492427Z",
     "shell.execute_reply": "2024-04-16T14:35:36.491146Z",
     "shell.execute_reply.started": "2024-04-16T14:35:31.789373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12954374\n"
     ]
    }
   ],
   "source": [
    "pc = lp.read(os.path.join(TRAIN_DIR, all_train_files[0])) \n",
    "train_loader =BatchLoader(pc)\n",
    "train_batches = train_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c9e16-062e-4df1-b55b-1e0c93a73f22",
   "metadata": {},
   "source": [
    "# Creat Pointnet++ for segmentation and pass it to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8641c6a0-06a7-407a-b747-b5883de7083d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:36:42.839175Z",
     "iopub.status.busy": "2024-04-16T14:36:42.838637Z",
     "iopub.status.idle": "2024-04-16T14:36:42.950741Z",
     "shell.execute_reply": "2024-04-16T14:36:42.949278Z",
     "shell.execute_reply.started": "2024-04-16T14:36:42.839131Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, train_dataset.num_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133e200-348e-46d3-bf10-ec14244edfc8",
   "metadata": {},
   "source": [
    "# Define train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c1a8374-683d-41fa-886b-1503c075f958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:51:16.834546Z",
     "iopub.status.busy": "2024-04-16T14:51:16.833839Z",
     "iopub.status.idle": "2024-04-16T14:51:16.847922Z",
     "shell.execute_reply": "2024-04-16T14:51:16.845908Z",
     "shell.execute_reply.started": "2024-04-16T14:51:16.834489Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    accuracy = 0.0\n",
    "    for i, data in enumerate(train_batches):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "        total_nodes += data.num_nodes\n",
    "        \n",
    "        accuracy = correct_nodes / total_nodes\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'[{i+1}/{len(train_batches)}] Loss: {total_loss / 10:.4f} '\n",
    "                  f'Train Acc: {correct_nodes / total_nodes:.4f}')\n",
    "            total_loss = correct_nodes = total_nodes = 0\n",
    "    return accuracy, total_loss\n",
    "                \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38408eba-3320-40c4-87fc-15a218194aef",
   "metadata": {},
   "source": [
    "# Define test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65ba4db1-7f97-4ac9-9163-49a731df31e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:36:25.334244Z",
     "iopub.status.busy": "2024-04-16T14:36:25.333709Z",
     "iopub.status.idle": "2024-04-16T14:36:25.350095Z",
     "shell.execute_reply": "2024-04-16T14:36:25.347305Z",
     "shell.execute_reply.started": "2024-04-16T14:36:25.334202Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    ious, categories = [], []\n",
    "    y_map = torch.empty(loader.data.num_classes, device=device).long()\n",
    "    test_batches = loader.load()\n",
    "    for data in test_batches:\n",
    "        data = data.to(device)\n",
    "        outs = model(data)\n",
    "\n",
    "        sizes = (data.ptr[1:] - data.ptr[:-1]).tolist()\n",
    "        for out, y, category in zip(outs.split(sizes), data.y.split(sizes),\n",
    "                                    data.category.tolist()):\n",
    "            category = list(ShapeNet.seg_classes.keys())[category]\n",
    "            part = ShapeNet.seg_classes[category]\n",
    "            part = torch.tensor(part, device=device)\n",
    "\n",
    "            y_map[part] = torch.arange(part.size(0), device=device)\n",
    "\n",
    "            iou = jaccard_index(out[:, part].argmax(dim=-1), y_map[y],\n",
    "                                num_classes=part.size(0), absent_score=1.0)\n",
    "            ious.append(iou)\n",
    "\n",
    "        categories.append(data.category)\n",
    "\n",
    "    iou = torch.tensor(ious, device=device)\n",
    "    category = torch.cat(categories, dim=0)\n",
    "\n",
    "    mean_iou = scatter(iou, category, reduce='mean')  # Per-category IoU.\n",
    "    return float(mean_iou.mean())  # Global IoU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eddfb21-048b-4236-8e01-b47a53d1c000",
   "metadata": {},
   "source": [
    "# Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1269f911-568d-45ed-b000-83b1367e9ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T14:51:20.629799Z",
     "iopub.status.busy": "2024-04-16T14:51:20.629256Z",
     "iopub.status.idle": "2024-04-16T14:55:35.512147Z",
     "shell.execute_reply": "2024-04-16T14:55:35.510622Z",
     "shell.execute_reply.started": "2024-04-16T14:51:20.629753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/405] Loss: 0.6338 Train Acc: 0.8065\n",
      "[20/405] Loss: 0.6758 Train Acc: 0.7641\n",
      "[30/405] Loss: 0.6602 Train Acc: 0.7652\n",
      "[40/405] Loss: 0.6724 Train Acc: 0.7633\n",
      "[50/405] Loss: 0.5891 Train Acc: 0.8026\n",
      "[60/405] Loss: 0.6425 Train Acc: 0.7594\n",
      "[70/405] Loss: 0.6939 Train Acc: 0.7692\n",
      "[80/405] Loss: 0.6278 Train Acc: 0.7719\n",
      "[90/405] Loss: 0.6990 Train Acc: 0.7319\n",
      "[100/405] Loss: 0.6408 Train Acc: 0.7809\n",
      "[110/405] Loss: 0.6192 Train Acc: 0.7843\n",
      "[120/405] Loss: 0.6460 Train Acc: 0.7657\n",
      "[130/405] Loss: 0.5604 Train Acc: 0.8034\n",
      "[140/405] Loss: 0.6874 Train Acc: 0.7533\n",
      "[150/405] Loss: 0.6022 Train Acc: 0.7902\n",
      "[160/405] Loss: 0.5872 Train Acc: 0.7868\n",
      "[170/405] Loss: 0.7004 Train Acc: 0.7515\n",
      "[180/405] Loss: 0.7040 Train Acc: 0.7483\n",
      "[190/405] Loss: 0.6913 Train Acc: 0.7405\n",
      "[200/405] Loss: 0.7014 Train Acc: 0.7314\n",
      "[210/405] Loss: 0.6890 Train Acc: 0.7877\n",
      "[220/405] Loss: 0.8458 Train Acc: 0.7068\n",
      "[230/405] Loss: 1.0345 Train Acc: 0.6278\n",
      "[240/405] Loss: 1.0105 Train Acc: 0.5926\n",
      "[250/405] Loss: 0.9275 Train Acc: 0.6476\n",
      "[260/405] Loss: 0.9341 Train Acc: 0.6603\n",
      "[270/405] Loss: 0.8878 Train Acc: 0.6783\n",
      "[280/405] Loss: 0.8407 Train Acc: 0.7060\n",
      "[290/405] Loss: 0.8828 Train Acc: 0.6849\n",
      "[300/405] Loss: 0.9698 Train Acc: 0.6309\n",
      "[310/405] Loss: 0.8684 Train Acc: 0.6958\n",
      "[320/405] Loss: 0.8919 Train Acc: 0.6752\n",
      "[330/405] Loss: 0.8305 Train Acc: 0.7162\n",
      "[340/405] Loss: 0.8650 Train Acc: 0.6964\n",
      "[350/405] Loss: 0.8170 Train Acc: 0.7066\n",
      "[360/405] Loss: 0.8170 Train Acc: 0.7088\n",
      "[370/405] Loss: 0.7979 Train Acc: 0.7166\n",
      "[380/405] Loss: 0.7640 Train Acc: 0.7306\n",
      "[390/405] Loss: 0.8597 Train Acc: 0.6926\n",
      "[400/405] Loss: 0.8840 Train Acc: 0.6828\n"
     ]
    }
   ],
   "source": [
    "best_iou = 0.0\n",
    "for epoch in range(1, 31):\n",
    "    accuracy, loss = train()\n",
    "    iou = test(test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Test IoU: {iou:.4f}')\n",
    "    if iou>best_iou: \n",
    "        best_iou = iou\n",
    "        #Save model\n",
    "        print(f\"Saving best model with IoU:{iou:.4f}\")\n",
    "        torch.save({'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss}, \n",
    "            'models/best.pt')\n",
    "\n",
    "    break\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
