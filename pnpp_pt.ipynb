{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2efa875-7897-4d1b-a54c-4db96ad21f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:42:36.464176Z",
     "iopub.status.busy": "2024-04-16T12:42:36.463626Z",
     "iopub.status.idle": "2024-04-16T12:42:36.476866Z",
     "shell.execute_reply": "2024-04-16T12:42:36.471837Z",
     "shell.execute_reply.started": "2024-04-16T12:42:36.464122Z"
    }
   },
   "outputs": [],
   "source": [
    "# !tar -xvzf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5403fa81-608c-4b08-8c95-b7f52726f66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:42:36.480983Z",
     "iopub.status.busy": "2024-04-16T12:42:36.479878Z",
     "iopub.status.idle": "2024-04-16T12:46:20.398283Z",
     "shell.execute_reply": "2024-04-16T12:46:20.396751Z",
     "shell.execute_reply.started": "2024-04-16T12:42:36.480925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cpu)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.17.2%2Bcu121-cp38-cp38-linux_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.2.2%2Bcu121-cp38-cp38-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.3)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.2.2%2Bcu121-cp38-cp38-linux_x86_64.whl (757.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.3/757.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.2.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.2)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.2\n",
      "    Uninstalling typing_extensions-4.6.2:\n",
      "      Successfully uninstalled typing_extensions-4.6.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1+cpu\n",
      "    Uninstalling torch-1.13.1+cpu:\n",
      "      Successfully uninstalled torch-1.13.1+cpu\n",
      "Successfully installed filelock-3.9.0 fsspec-2023.4.0 mpmath-1.3.0 networkx-3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 pillow-10.2.0 sympy-1.12 torch-2.2.2+cu121 torchaudio-2.2.2+cu121 torchvision-0.17.2+cu121 triton-2.2.0 typing-extensions-4.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch-scatter 2.1.0+pt113cpu\n",
      "Uninstalling torch-scatter-2.1.0+pt113cpu:\n",
      "  Successfully uninstalled torch-scatter-2.1.0+pt113cpu\n",
      "Found existing installation: torch-sparse 0.6.16+pt113cpu\n",
      "Uninstalling torch-sparse-0.6.16+pt113cpu:\n",
      "  Successfully uninstalled torch-sparse-0.6.16+pt113cpu\n",
      "\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "poptorch-geometric 3.2.0+112435 requires torch-sparse@ https://data.pyg.org/whl/torch-1.13.0%2Bcpu/torch_sparse-0.6.16+pt113cpu-cp38-cp38-linux_x86_64.whl, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyvis\n",
      "  Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.1/301.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from pyvis) (7.16.3)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.8/dist-packages (from pyvis) (3.1.2)\n",
      "Collecting jsonpickle>=1.4.1 (from pyvis)\n",
      "  Downloading jsonpickle-3.0.4-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.8/dist-packages (from pyvis) (3.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (2.2.2+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (67.8.0)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.17.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (5.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (3.0.38)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (2.15.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2023.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from jedi<=0.17.2,>=0.10->ipython>=5.3.0->pyvis) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.6)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, kiwisolver, jsonpickle, fonttools, cycler, contourpy, matplotlib, pyvis, torchmetrics\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.51.0 jsonpickle-3.0.4 kiwisolver-1.4.5 lightning-utilities-0.11.2 matplotlib-3.7.5 pyvis-0.3.2 torchmetrics-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting laspy\n",
      "  Downloading laspy-2.5.3-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from laspy) (1.24.3)\n",
      "Installing collected packages: laspy\n",
      "Successfully installed laspy-2.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting hydra-core\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from hydra-core) (23.1)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core) (5.12.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (5.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core) (3.15.0)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144553 sha256=0a5ee68552f7ccfb044b685e3eb982154cba2b10a5767639bf57d6b3384dbddd\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip uninstall torch-scatter torch-sparse torch-cluster -y\n",
    "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q torch-cluster -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html --no-cache-dir\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "!pip install matplotlib pyvis torchmetrics\n",
    "!pip install laspy\n",
    "!pip install hydra-core \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fef1e0d-16b3-42af-8131-6cb6e9bfe31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:20.403944Z",
     "iopub.status.busy": "2024-04-16T12:46:20.403431Z",
     "iopub.status.idle": "2024-04-16T12:46:21.030846Z",
     "shell.execute_reply": "2024-04-16T12:46:21.028592Z",
     "shell.execute_reply.started": "2024-04-16T12:46:20.403900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 12:46:20 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P4000        Off  | 00000000:00:05.0 Off |                  N/A |\n",
      "| 46%   39C    P8     5W / 105W |      2MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:00:05.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9801aaa-1307-401b-a29d-e845a6deae6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:21.034324Z",
     "iopub.status.busy": "2024-04-16T12:46:21.033800Z",
     "iopub.status.idle": "2024-04-16T12:46:31.826258Z",
     "shell.execute_reply": "2024-04-16T12:46:31.824316Z",
     "shell.execute_reply.started": "2024-04-16T12:46:21.034280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os.path as osp\n",
    "import os\n",
    "import laspy as lp\n",
    "import numpy as np\n",
    "import hydra\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import jaccard_index\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius,knn_interpolate\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ca5f13-f4ed-456b-b5ae-b284c930fcef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.829154Z",
     "iopub.status.busy": "2024-04-16T12:46:31.828483Z",
     "iopub.status.idle": "2024-04-16T12:46:31.839132Z",
     "shell.execute_reply": "2024-04-16T12:46:31.836425Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.829117Z"
    }
   },
   "outputs": [],
   "source": [
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7747aa-2382-4f89-a3a2-6b5cdeb1f32c",
   "metadata": {},
   "source": [
    "## Define PointNet++ Segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72ce8472-4782-4289-9e3d-9cbf3161ef3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:46:05.238967Z",
     "iopub.status.busy": "2024-04-16T13:46:05.238353Z",
     "iopub.status.idle": "2024-04-16T13:46:05.253280Z",
     "shell.execute_reply": "2024-04-16T13:46:05.251842Z",
     "shell.execute_reply.started": "2024-04-16T13:46:05.238914Z"
    }
   },
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        \n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        \n",
    "        print(f\"idx shape: {idx.shape}\")\n",
    "        print(f\"x shape: {x.shape}\")\n",
    "        print(f\"pos shape: {pos.shape}\")\n",
    "        print(f\"x_dst shape: {x_dst.shape}\")\n",
    "        print(f\"edge_index shape: {edge_index.shape}\")\n",
    "        \n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd03b64-c731-4e6c-b727-977fc5cd9ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.858817Z",
     "iopub.status.busy": "2024-04-16T12:46:31.858378Z",
     "iopub.status.idle": "2024-04-16T12:46:31.871663Z",
     "shell.execute_reply": "2024-04-16T12:46:31.869576Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.858781Z"
    }
   },
   "outputs": [],
   "source": [
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0b5e36-c0e8-4e10-929b-c26ea88eec07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.874908Z",
     "iopub.status.busy": "2024-04-16T12:46:31.874291Z",
     "iopub.status.idle": "2024-04-16T12:46:31.893143Z",
     "shell.execute_reply": "2024-04-16T12:46:31.889679Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.874859Z"
    }
   },
   "outputs": [],
   "source": [
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e071dfe-5e7e-4ba1-b7e4-9b66b04255ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:47:45.838281Z",
     "iopub.status.busy": "2024-04-16T13:47:45.837784Z",
     "iopub.status.idle": "2024-04-16T13:47:45.853959Z",
     "shell.execute_reply": "2024-04-16T13:47:45.851927Z",
     "shell.execute_reply.started": "2024-04-16T13:47:45.838249Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes , num_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        # self.sa1_module = SAModule(0.2, 0.2, MLP([3 + 3, 64, 64, 128]))\n",
    "        self.sa1_module = SAModule(0.2, 0.2, MLP([3 + num_features, 64, 64, 128]))\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([1024 + 256, 256, 256]))\n",
    "        self.fp2_module = FPModule(3, MLP([256 + 128, 256, 128]))\n",
    "        self.fp1_module = FPModule(3, MLP([128 + num_features, 128, 128, 128]))\n",
    "\n",
    "        self.mlp = MLP([128, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        # self.lin1 = torch.nn.Linear(128, 128)\n",
    "        # self.lin2 = torch.nn.Linear(128, 128)\n",
    "        # self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "\n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30770fbd-1c1b-4c40-a044-aa74b6c9277b",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a492349-5e85-4638-aaac-88e611c5e505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.923037Z",
     "iopub.status.busy": "2024-04-16T12:46:31.922471Z",
     "iopub.status.idle": "2024-04-16T12:46:31.934544Z",
     "shell.execute_reply": "2024-04-16T12:46:31.932719Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.922990Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get all las file for training \n",
    "TRAIN_DIR = \"dales_las/train/\" \n",
    "TEST_DIR = \"dales_las/test/\"\n",
    "\n",
    "all_train_files = os.listdir(osp.abspath(TRAIN_DIR))\n",
    "all_test_files  = os.listdir(osp.abspath(TEST_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08cff59-f71c-4af2-ba82-ee324e479b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T12:46:31.936818Z",
     "iopub.status.busy": "2024-04-16T12:46:31.936274Z",
     "iopub.status.idle": "2024-04-16T12:46:33.135232Z",
     "shell.execute_reply": "2024-04-16T12:46:33.133618Z",
     "shell.execute_reply.started": "2024-04-16T12:46:31.936743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Y\n",
      "Z\n",
      "intensity\n",
      "return_number\n",
      "number_of_returns\n",
      "scan_direction_flag\n",
      "edge_of_flight_line\n",
      "classification\n",
      "synthetic\n",
      "key_point\n",
      "withheld\n",
      "scan_angle_rank\n",
      "user_data\n",
      "point_source_id\n",
      "gps_time\n"
     ]
    }
   ],
   "source": [
    "pc = lp.read(os.path.join(TRAIN_DIR, all_train_files[0])) \n",
    "for dimension in pc.point_format.dimensions:\n",
    "    print(dimension.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f03475d5-736b-4e36-a093-48b40530e03c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:42:00.518790Z",
     "iopub.status.busy": "2024-04-16T13:42:00.518185Z",
     "iopub.status.idle": "2024-04-16T13:42:00.537248Z",
     "shell.execute_reply": "2024-04-16T13:42:00.535345Z",
     "shell.execute_reply.started": "2024-04-16T13:42:00.518744Z"
    }
   },
   "outputs": [],
   "source": [
    "def convertData(pc):\n",
    "    #Define preprocessing steps\n",
    "    num_to_load = 32000\n",
    "    transform = T.Compose([\n",
    "        T.RandomJitter(0.01),\n",
    "        T.RandomRotate(15, axis=0),\n",
    "        T.RandomRotate(15, axis=1),\n",
    "        T.RandomRotate(15, axis=2)\n",
    "        ])\n",
    "    pre_transform = T.NormalizeScale()\n",
    "    \n",
    "    #Get imformation from las file\n",
    "    coords = np.vstack((pc.x, pc.y, pc.z)).transpose()    \n",
    "    scales = pc.header.scales\n",
    "    offsets= pc.header.offsets    \n",
    "    scaled_coords = (coords * scales) + offsets\n",
    "    \n",
    "    labels = pc.classification.array\n",
    "    features = pc.intensity if np.max(pc.intensity) > 0 else np.ones_like(pc.intensity, dtype = np.uint8)\n",
    "    if len(features.shape) <2: \n",
    "        features = features[:, np.newaxis]\n",
    "    num_classes = len(np.unique(labels))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(features.shape)\n",
    "    print(coords.shape)\n",
    "    print(scaled_coords.shape)\n",
    "    print(labels.shape)\n",
    "    print(np.unique(labels))\n",
    "    return Data(x = torch.from_numpy(features[:num_to_load]), \n",
    "                pos = torch.from_numpy(scaled_coords[:num_to_load]).type(torch.FloatTensor), \n",
    "                y = torch.from_numpy(labels[:num_to_load]), \n",
    "                num_classes=num_classes,\n",
    "                num_features = features.shape[-1],\n",
    "               transform = transform, \n",
    "               pre_transform= pre_transform,\n",
    "               batch = torch.from_numpy(np.zeros_like(features[:num_to_load],dtype = np.int64)).flatten()\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c67470a-af11-47a7-8076-964475835532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:42:02.451180Z",
     "iopub.status.busy": "2024-04-16T13:42:02.450580Z",
     "iopub.status.idle": "2024-04-16T13:42:09.192872Z",
     "shell.execute_reply": "2024-04-16T13:42:09.190316Z",
     "shell.execute_reply.started": "2024-04-16T13:42:02.451134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12954374, 1)\n",
      "(12954374, 3)\n",
      "(12954374, 3)\n",
      "(12954374,)\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "Data(x=[32000, 1], y=[32000], pos=[32000, 3], num_classes=9, num_features=1, transform=Compose([\n",
      "  RandomJitter(0.01),\n",
      "  RandomRotate((-15, 15), axis=0),\n",
      "  RandomRotate((-15, 15), axis=1),\n",
      "  RandomRotate((-15, 15), axis=2)\n",
      "]), pre_transform=NormalizeScale(), batch=[32000])\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "\n",
    "pc = lp.read(os.path.join(TRAIN_DIR, all_train_files[0])) \n",
    "train_dataset = convertData(pc)\n",
    "print(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a2f0b6-75a3-466f-8120-036ade924644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:06:23.398910Z",
     "iopub.status.busy": "2024-04-16T13:06:23.398508Z",
     "iopub.status.idle": "2024-04-16T13:06:23.405115Z",
     "shell.execute_reply": "2024-04-16T13:06:23.403259Z",
     "shell.execute_reply.started": "2024-04-16T13:06:23.398881Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = ShapeNet(path, category, split='trainval', force_reload=True)\n",
    "# test_dataset = ShapeNet(path, category, split='test',\n",
    "#                         pre_transform=pre_transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True,  num_workers=6)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=12, shuffle=False,\n",
    "#                          num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62016b99-f94b-4430-8091-f9357dc77ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:06:24.098510Z",
     "iopub.status.busy": "2024-04-16T13:06:24.098069Z",
     "iopub.status.idle": "2024-04-16T13:06:24.104144Z",
     "shell.execute_reply": "2024-04-16T13:06:24.102664Z",
     "shell.execute_reply.started": "2024-04-16T13:06:24.098479Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bae4ec4e-131a-4da1-a8c2-a02bb30bca8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:47:57.319034Z",
     "iopub.status.busy": "2024-04-16T13:47:57.318404Z",
     "iopub.status.idle": "2024-04-16T13:47:57.425348Z",
     "shell.execute_reply": "2024-04-16T13:47:57.423682Z",
     "shell.execute_reply.started": "2024-04-16T13:47:57.318979Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, train_dataset.num_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1269f911-568d-45ed-b000-83b1367e9ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:47:58.759032Z",
     "iopub.status.busy": "2024-04-16T13:47:58.758474Z",
     "iopub.status.idle": "2024-04-16T13:47:59.567450Z",
     "shell.execute_reply": "2024-04-16T13:47:59.566055Z",
     "shell.execute_reply.started": "2024-04-16T13:47:58.758981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx shape: torch.Size([6400])\n",
      "x shape: torch.Size([32000, 1])\n",
      "pos shape: torch.Size([32000, 3])\n",
      "x_dst shape: torch.Size([6400, 1])\n",
      "edge_index shape: torch.Size([2, 409600])\n",
      "idx shape: torch.Size([1600])\n",
      "x shape: torch.Size([6400, 128])\n",
      "pos shape: torch.Size([6400, 3])\n",
      "x_dst shape: torch.Size([1600, 128])\n",
      "edge_index shape: torch.Size([2, 102400])\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data = train_dataset\n",
    "total_loss = correct_nodes = total_nodes = 0\n",
    "data = data.to(device)\n",
    "optimizer.zero_grad()\n",
    "out = model(data)\n",
    "loss = F.nll_loss(out, data.y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "total_loss += loss.item()\n",
    "correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "total_nodes += data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73073dd9-5fea-4a3d-be2e-6749a19efcf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-16T13:49:04.603280Z",
     "iopub.status.busy": "2024-04-16T13:49:04.602859Z",
     "iopub.status.idle": "2024-04-16T13:49:04.614081Z",
     "shell.execute_reply": "2024-04-16T13:49:04.612239Z",
     "shell.execute_reply.started": "2024-04-16T13:49:04.603248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1098e+03, 5.4461e+04, 5.1390e-01],\n",
      "        [5.1098e+03, 5.4461e+04, 5.1440e-01],\n",
      "        [5.1098e+03, 5.4461e+04, 5.1410e-01],\n",
      "        ...,\n",
      "        [5.1098e+03, 5.4461e+04, 5.2100e-01],\n",
      "        [5.1099e+03, 5.4462e+04, 5.2410e-01],\n",
      "        [5.1098e+03, 5.4461e+04, 5.7960e-01]], device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390efb06-8504-46af-be0c-3170f4b10011",
   "metadata": {},
   "source": [
    "## Creat Pointnet++ for segmentation and pass it to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114d5ea-e685-4d42-8e61-179b12edf6a0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.508507Z",
     "iopub.status.idle": "2024-04-16T12:46:50.509203Z",
     "shell.execute_reply": "2024-04-16T12:46:50.508916Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f818a7-8b1f-4526-8514-6f763e5d30dc",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0161d0f-f97f-431a-9a58-b639039ede58",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.511541Z",
     "iopub.status.idle": "2024-04-16T12:46:50.512220Z",
     "shell.execute_reply": "2024-04-16T12:46:50.511952Z"
    }
   },
   "outputs": [],
   "source": [
    "category = 'Airplane'  # Pass in `None` to train on all categories.\n",
    "path = osp.join(osp.dirname(os.getcwd()), '..', 'data', 'ShapeNet')\n",
    "transform = T.Compose([\n",
    "    T.RandomJitter(0.01),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2)\n",
    "])\n",
    "pre_transform = T.NormalizeScale()\n",
    "\n",
    "transform = None\n",
    "pre_transforms = None \n",
    "# train_dataset = ShapeNet(path, category, split='trainval', transform=transform,\n",
    "#                          pre_transform=pre_transform)\n",
    "train_dataset = ShapeNet(path, category, split='trainval', force_reload=True)\n",
    "test_dataset = ShapeNet(path, category, split='test',\n",
    "                        pre_transform=pre_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=15, shuffle=True,\n",
    "                          num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=15, shuffle=False,\n",
    "                         num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569df8a2-93f0-45d2-b5fe-51caf5a4e24b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.513634Z",
     "iopub.status.idle": "2024-04-16T12:46:50.514356Z",
     "shell.execute_reply": "2024-04-16T12:46:50.514057Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_dataset.x.shape)\n",
    "print(train_dataset.nodes.shape)\n",
    "for data in train_loader:\n",
    "    print(data.batch.shape)\n",
    "    print(train_dataset.x.shape[0]// data.batch.shape[0])\n",
    "    print(np.unique(data.batch, return_counts=True))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcbe84-4fac-488d-952d-3ee10892ee2f",
   "metadata": {},
   "source": [
    "## Define train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961d349-50d2-4ee2-bf70-b4e9962e640f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.516132Z",
     "iopub.status.idle": "2024-04-16T12:46:50.516695Z",
     "shell.execute_reply": "2024-04-16T12:46:50.516487Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "        total_nodes += data.num_nodes\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / 10:.4f} '\n",
    "                  f'Train Acc: {correct_nodes / total_nodes:.4f}')\n",
    "            total_loss = correct_nodes = total_nodes = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b169b-d654-49c9-8b6a-0c5cfdbf9703",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.518726Z",
     "iopub.status.idle": "2024-04-16T12:46:50.519598Z",
     "shell.execute_reply": "2024-04-16T12:46:50.519233Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).max(1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5131c-06f0-4ca0-953a-ccf2087d32e3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.521285Z",
     "iopub.status.idle": "2024-04-16T12:46:50.522119Z",
     "shell.execute_reply": "2024-04-16T12:46:50.521773Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = Net().to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for epoch in range(1, 201):\n",
    "#     train(epoch)\n",
    "#     test_acc = test(test_loader)\n",
    "#     print(f'Epoch: {epoch:03d}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d466a-0237-47bf-a021-58b1e50dd1ff",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-16T12:46:50.523994Z",
     "iopub.status.idle": "2024-04-16T12:46:50.524745Z",
     "shell.execute_reply": "2024-04-16T12:46:50.524428Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1748f9-37c5-4c26-9811-8c4dd440282c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
